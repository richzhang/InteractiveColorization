<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1250px;
	}	
	h1 {
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 0px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Real-Time User-Guided Image Colorization with Learned Deep Priors</title>
		<meta property="og:image" content="https://richzhang.github.io/ideepcolor/index_files/teaser_v3.jpg"/>
		<meta property="og:title" content="Real-Time User-Guided Image Colorization with Learned Deep Priors. In SIGGRAPH, 2017." />
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:42px">Real-Time User-Guided Image Colorization with Learned Deep Priors</span><br>
	  		  <table align=center width=950px>
	  		  <!-- <table align=center width=540px> -->
	  			  <tr>
	  	              <td align=center width=140px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://richzhang.github.io/">Richard Zhang*</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=140px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu*</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=140px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://web.mit.edu/phillipi/">Phillip Isola</a></span>
		  		  		</center>
		  		  	  </td>
	  			  <!-- </tr> -->
	  		  <!-- </table> -->
	  		  <!-- <table align=center width=600px> -->
	  			  <!-- <tr> -->
	  	              <td align=center width=140px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://young-geng.xyz//">Xinyang Geng</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=140px>
	  					<center>
	  						<!-- <span style="font-size:24px"><a href="http://people.eecs.berkeley.edu/~junyanz/">Angela S. Lin</a></span> -->
	  						<span style="font-size:18px">Angela S. Lin</span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=140px>
	  					<center>
	  						<!-- <span style="font-size:24px"><a href="http://web.mit.edu/phillipi/">Tianhe Yu</a></span> -->
	  						<span style="font-size:18px">Tianhe Yu</span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=140px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></span>
		  		  		</center>
		  		  	  </td>
	  			  </tr>
			  </table>
          	<!-- <span style="font-size:16px">(*indicates equal contribution)</span><br> -->
          	<span style="font-size:18px"><b>University of California, Berkeley</b></span>
	  		  <table align=center width=800px>
	  			  <tr>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:22px">Code <a href='https://github.com/junyanz/interactive-deep-colorization'> [GitHub]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=275px>
	  					<center>
	  						<span style="font-size:22px">SIGGRAPH 2017<a href='https://arxiv.org/abs/1705.02999'> [Paper]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:22px">Seminar<a href='https://youtu.be/FTzcFsz2xqw?t=992'> [Talk]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:22px">Slides<a href='https://www.dropbox.com/s/urmifx558nw0ogi/release.pptx?dl=0'> [ppt]</a></span>
		  		  		</center>
		  		  	  </td>
			  </table>
          </center>

  		  <table align=center width=900px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<img class="rounded" src = "./index_files/teaser_v3.jpg" height="275px"></img>
  	                	<br>
					</center>
  	              </td>
  	              </tr>
  	              </table>

  		  <br>
		  <hr>

  		  <table align=center width=900px>
	  		 	<center><h1>Abstract</h1></center>
				We propose a deep learning approach for user-guided image colorization. The system directly maps a grayscale image, along with sparse, local user ``hints" to an output colorization with a Convolutional Neural Network (CNN). Rather than using hand-defined rules, the network propagates user edits by fusing low-level cues along with high-level semantic information, <i>learned from large-scale data</i>. We train on a million images, with simulated user inputs. To guide the user towards efficient input selection, the system recommends likely colors based on the input image and current user inputs. The colorization is performed in a single feed-forward pass, enabling real-time use. Even with randomly simulated user inputs, we show that the proposed system helps novice users quickly create realistic colorizations, and show large improvements in colorization quality with just a minute of use. In addition, we show that the framework can incorporate other user "hints" as to the desired colorization, showing an application to color histogram transfer.
  		  <br>
		  <hr>

  		  <table align=center width=900px>
	  		 	<center><h1>Demo Video</h1></center>
  			  <tr>
<!--   	              <td width=400px>
  					<center>
  	                	<img class="rounded" src = "./index_files/teaser_v3.jpg" height="275px"></img>
  	                	<br>
					</center>
  	              </td> -->
		  		  <table align=center width=600px>
		  		    <tr>
		              <td align=center width=600px>
						<iframe width="800" height="450" src="https://www.youtube.com/embed/eL5ilZgM89Q" frameborder="0" allowfullscreen></iframe>
					  </td>
					</tr>
				  </table>
				<br>
                </tr>
  		  </table>

        <center><a href="https://www.dropbox.com/s/mfi66auuv7qzyx0/iColor_release.mp4?dl=0">mp4</a></center>
  		  <br>
		  <hr>

 		<center><h1>Results on Legacy Photos</h1></center>

		We trained our system on 1.3M color photos, which were made grayscale "synthetically" (by removing the color components). Here, we show some examples on <i>legacy</i> grayscale photographs. This is Figure 10 in our full paper.

		<br>
  		  <table align=center width=600px>
  		    <tr>
              <td align=center width=600px>
        		<!-- <a href="./index_files/legacy_v4.jpg"><img class="rounded"  src = "./index_files/legacy_v4_small.jpg" width = "800px"></a><br> -->
        		<a href="http://colorization.eecs.berkeley.edu/siggraph/legacy_photos/"><img class="rounded"  src = "./index_files/legacy_v4_small.jpg" width = "800px"></a><br>
				<span style="font-size:16px"></span>
			  </td>
			</tr>
  			  <!-- <tr> -->
  	              <td align=center width=600px>
  					<center>
  						<span style="font-size:28px"><a href='http://colorization.eecs.berkeley.edu/siggraph/legacy_photos/'>Selected Legacy Photos</a></span>
	  		  		</center>
	  		  	  </td>
  		  	  <!-- </tr> -->
		  </table>

		<br>
		<hr>

 		<center><h1>Additional Results</h1></center>

 		We show all of the results from our user study. Each user spent just 1 minute on each image. Each of the 28 users was given minimal training (short 2 minute explanation, and a few questions), and given 10 images to colorize. We show all 280 examples in the link below.

 		This is an extension of Figures 4 & 5 of our paper. Please see Section 4.2 of our paper for additional details.

  		  <table align=center width=600px>
  		    <tr>
              <td align=center width=600px>
        		<a href="http://colorization.eecs.berkeley.edu/siggraph/user_study/"><img class="rounded"  src = "./index_files/imagenet_showcase_small.jpg" width = "800px"></a><br>
        		<!-- <a href="./index_files/imagenet_showcase.jpg"><img class="rounded"  src = "./index_files/imagenet_showcase_small.jpg" width = "800px"></a><br> -->
				<span style="font-size:16px"></span>
			  </td>
			</tr>
  			  <tr>
  	              <td align=center width=600px>
  					<center>
  						<span style="font-size:28px"><a href='http://colorization.eecs.berkeley.edu/siggraph/user_study/'> Full User Study Results</a></span>
	  		  		</center>
	  		  	  </td>
  		  	  </tr>
		  </table>
		<br>

 		We show additional examples of our network incorporating global histogram information. Please see Sections 3.3 and 4.4 for additional details. This is an extension of Figure 9 in our paper.

  		  <table align=center width=600px>
  		    <tr>
              <td align=center width=600px>
        		<!-- <a href="./index_files/lab_all_figures45k.jpg"><img class="rounded" src = "./index_files/lab_all_figures45k_small.jpg" width = "800px"></a><br> -->
        		<a href="http://colorization.eecs.berkeley.edu/siggraph/global_transfer/"><img class="rounded" src = "./index_files/lab_all_figures45k_small.jpg" width = "800px"></a><br>
				<span style="font-size:16px"></span>
			  </td>
			</tr>
  			  <tr>
  	              <td align=center width=600px>
  					<center>
  						<span style="font-size:28px"><a href='http://colorization.eecs.berkeley.edu/siggraph/global_transfer/'>Random Histogram Transfer Results</a></span>
	  		  		</center>
	  		  	  </td>
  		  	  </tr>
		  </table>
		<br>

<!--   		  <table align=center width=600px>
  		  	<tr>
  	              <td align=center width=300px>
  					<center>
  						<span style="font-size:22px"><a href='http://colorization.eecs.berkeley.edu/siggraph/global_transfer/'>Histogram Transfer Results</a></span>
	  		  		</center>
	  		  	  </td>
	  		</tr>
		  </table>
 -->
		  <hr>

 		<center><h1>Try the network</h1></center>
		  <!-- The GitHub page has scripts for fetching our model, and a slightly modified version of Caffe which does color pre-processing (if so desired). We recommend going to the <a href='https://github.com/richzhang/splitbrainauto'>GitHub</a> page and following instructions in the readme. -->

  		  <table align=center width=900px>
  			  <tr>
  	                <td align=center width=900px>
  					<center>
						  <td><a href='https://github.com/junyanz/interactive-deep-colorization'><img class="round" style="width:900px" src="./index_files/network4.jpg"/></a></td>
	  		  		</center>
	  		  		</td>
			  </tr>
		  </table>

  		  <table align=center width=800px>
			  <tr><center>
				<span style="font-size:28px"><a href='https://github.com/junyanz/iColor_release'>[GitHub]</a>
			  <br>
			  </center></tr>
			  <!-- <tr><center> -->
 			<!-- <span style="font-size:28px"><a>&nbsp;Model: [Prototxt] Weights: [Unrescaled] [Rescaled]</a></span> -->
			  <!-- </center></tr> -->
		  </table>

  		  <br>
		  <hr>

  		  <table align=center width=540 px>
	 		<center><h1>Paper</h1></center>
  			  <tr>
				  <td><a href="https://arxiv.org/abs/1705.02999"><img class="layered-paper-big" style="height:175px" src="./index_files/page1.png"/></a></td>
				  <td><span style="font-size:12pt">R. Zhang*, J.Y. Zhu*, P. Isola, <br> X. Geng, A. S. Lin, T. Yu, A. A. Efros.</span><br>
				  <b><span style="font-size:12pt">Real-Time User-Guided Image Colorization with Learned Deep Priors.</b></span><br>
				  <span style="font-size:12pt">In SIGGRAPH, 2017. (hosted on <a href="https://arxiv.org/abs/1705.02999">arXiv</a>)</span></a>
				  <span style="font-size:4pt"><a href=""><br></a>
				  </span>
				  </td>
  	              </td>
              </tr>
  		  </table>
		  <br>

		  <table align=center width=600px>
			  <tr>
				  <td><span style="font-size:24pt"><center>
				  	<a href="./index_files/bibtex_siggraph2017.txt">[Bibtex]</a>
  	              </center></td>
              </tr>
  		  </table>

  		  <br>
		  <hr>
		  	
  		  <table align=center width=1100px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Related and Concurrent Work</h1></center>
	  		  		<span style="font-size:24px"><center><b> Automatic Colorization with Deep Networks </b> </center></span><br>

					R. Zhang, P. Isola, A. A. Efros. <b>Colorful Image Colorization.</b> In ECCV, 2016. <a href="https://arxiv.org/abs/1603.08511">[PDF]</a><a href="http://richzhang.github.io/colorization/"> [Website]</a><a href="http://demos.algorithmia.com/colorize-photos/"> [Demo]</a></br>

					<br>

					G. Larsson, M. Maire, and G. Shakhnarovich. <b>Learning Representations for Automatic Colorization.</b> In ECCV, 2016. <a href="http://arxiv.org/pdf/1603.06668.pdf"> [PDF]</a><a href="http://people.cs.uchicago.edu/~larsson/colorization/"> [Website]</a></br>

					<br>

					S. Iizuka, E. Simo-Serra, and H. Ishikawa. <b>Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification.</b> In SIGGRAPH, 2016. <a href="http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/data/colorization_sig2016.pdf"> [PDF]<a href="http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/"> [Website]</a></a></br>

					<br>

	  		  		<span style="font-size:24px"><center><b> User Interaction with Deep Networks </b> </center></span><br>

					P. Isola, J.Y. Zhu, T. Zhou, A. A. Efros. <b>Image to Image Translation with Conditional Adversarial Networks.</b> In CVPR, 2017. <a href="https://arxiv.org/pdf/1611.07004.pdf"> [PDF]</a><a href="https://phillipi.github.io/pix2pix/"> [Website]</a><a href="https://affinelayer.com/pixsrv/"> [Demo]</a></br>

					<br>

					P. Sangkloy, J. Lu, C. Fang, F. Yu, J. Hays. <b>Scribbler: Controlling Deep Image Synthesis with Sketch and Color.</b> In CVPR, 2017. <a href="http://scribbler.eye.gatech.edu/paper.pdf"> [PDF]</a><a href="http://scribbler.eye.gatech.edu/"> [Website]</a></br>

					<br>

					J.Y. Zhu, P. Krähenbühl, E. Shechtman, A. A. Efros. <b>Generative Visual Manipulation on the Natural Image Manifold.</b> In ECCV, 2016. <a href="https://arxiv.org/pdf/1609.03552.pdf"> [PDF]</a><a href="http://people.eecs.berkeley.edu/~junyanz/projects/gvm/index.html"> [Website]</a></br>

					<br>

					K. Frans. <b>Outline Colorization through Tandem Adversarial Networks.</b> In Arxiv, 2017. <a href="https://arxiv.org/abs/1704.08834">[PDF]</a><a href="http://color.kvfrans.com/"> [Demo]</a></br>

					<br>

					Preferred Networks, Inc. <b>PaintsChainer.</b><a href="https://paintschainer.preferred.tech/"> [Demo]</a>

			</left>
		</td>
			 </tr>
		</table>
		<hr>

  		  <table align=center width=1100px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
				We thank members of the Berkeley Artificial Intelligence Research Lab for helpful discussions. We also thank the participants in our user study, along with Aditya Deshpande and Gustav Larsson for providing images for comparison. This work has been supported, in part, by NSF SMA-1514512, a Google Grant, BAIR, and a hardware donation by NVIDIA.
			</left>
		</td>
			 </tr>
		</table>

		<br><br>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75863369-3', 'auto');
  ga('send', 'pageview');

</script>
              
</body>
</html>
 
